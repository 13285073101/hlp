
Human-like Planning

This is the "Human-like Planning (HLP)" project. Our objective in this project is to learn human planning skills from VR demonstartions and transfer these skills to robot motion planners. The VR dataset and the source code are released here. More information are givven in ICRA 2020 paper [1]. 

To go through the datset and do some visualization, run dataset_demo.m

To train the decision classifiers, run 

To test the overall HLP algorithm, run


For queries about the HLP algorithm, please contact Mohamed Hasan (m.hasan@leeds.ac.uk).
For queries about the VR dataset, please contact Matthew Warburton (m.warburton@leeds.ac.uk).  
 

If you used this code and/or dataset in academia, please cite the following work:  


[1] M. Hasan, M. Warburton, W. C. Agboh, M. R. Dogar, M. Leonetti, H. Wang, F. Mushtaq, M. Mon-Williams and A. G. Cohn, “Introducing a Human-like Planner for Reaching in Cluttered Environments, ” Accepted to ICRA 2020.

